this project presents an intelligent indoor guiding robot designed for multi-floor environments. The system features voice interaction, visual perception, and cross-floor navigation capabilities. By integrating speech recognition, semantic parsing, YOLO-based object detection, and SLAM mapping, the robot enables voice-controlled autonomous navigation and guidance across complex indoor spaces.

